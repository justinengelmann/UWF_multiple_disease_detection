{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f48b0a8-eb1a-42a3-9834-ebbfdf5cee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timm version: 0.5.4\n",
      "Actual output:   tensor([-2.7877, -2.8305, -2.9748, -2.2224, -3.2804, -2.4505,  1.1078,  1.3486])\n",
      "Expected output: tensor([-2.7877, -2.8305, -2.9748, -2.2224, -3.2804, -2.4505,  1.1078,  1.3486])\n",
      "Diff (rounded):  tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "\n",
    "model = torch.load('TOP_UWF_ema_model.pt')\n",
    "# you can use the jit version for better compatability\n",
    "# model = torch.jit.load('TOP_UWF_ema_model_jit.pt')\n",
    "model.eval().cpu()\n",
    "\n",
    "print(f'timm version: {timm.__version__}')\n",
    "# hacky fix in case you are using timm version > 4.10; please use the versions in the requirements.txt and/or try to jit version if these tests don't work\n",
    "model.global_pool.flatten = torch.nn.Flatten(1)\n",
    "\n",
    "#### TEST INPUT-OUTPUT\n",
    "# b, c, h, w\n",
    "test_input = torch.zeros(1, 2, 384, 512)\n",
    "# expected output for all zero tensor of shape (1,2,384,512), rounded to four decimal places; in logit space\n",
    "expected_output = torch.tensor([-2.7877, -2.8305, -2.9748, -2.2224, -3.2804, -2.4505,  1.1078,  1.3486])\n",
    "with torch.no_grad():\n",
    "    actual_output = model(test_input).flatten()\n",
    "    print(f'Actual output:   {actual_output}')\n",
    "    print(f'Expected output: {expected_output}')\n",
    "    print(f'Diff (rounded):  {expected_output - actual_output.round(decimals=4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f8cc96-e1c6-41d1-8810-84d887432ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-24 18:51:04--  https://i.redd.it/hij0f9pkqn441.jpg?raw=true\n",
      "Resolving i.redd.it (i.redd.it)... 199.232.57.140, 2a04:4e42:4b::396\n",
      "Connecting to i.redd.it (i.redd.it)|199.232.57.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45020 (44K) [image/jpeg]\n",
      "Saving to: ‘test_img_RP.jpg’\n",
      "\n",
      "test_img_RP.jpg     100%[===================>]  43.96K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2022-07-24 18:51:04 (3.63 MB/s) - ‘test_img_RP.jpg’ saved [45020/45020]\n",
      "\n",
      "Actual output:   tensor([0.0622, 0.9177, 0.0537, 0.0322, 0.0666, 0.0957, 0.0739, 0.9620])\n",
      "Expected output: tensor([0.0622, 0.9177, 0.0537, 0.0322, 0.0666, 0.0957, 0.0739, 0.9620])\n",
      "Diff (rounded):  tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "This external validation set image (adapted from Antaki et al.'s external validation set, which also includes this image) shows RP.\n",
      "So, our model should predict RP and \"any\" (i.e. any disease) with high probabilities,\n",
      "and the rest with low probabilities (bearing in mind that we used label smoothing,\n",
      "so our model tries to predict approximately 5% if a label is absent and 99% if it is present.)\n",
      "\n",
      "Here is what we got:\n",
      "Predicted  MH with probability: 0.0622 (or 6.22%)\n",
      "Predicted  RP with probability: 0.9177 (or 91.77%)\n",
      "Predicted AMD with probability: 0.0537 (or 5.37%)\n",
      "Predicted RVO with probability: 0.0322 (or 3.22%)\n",
      "Predicted  RD with probability: 0.0666 (or 6.66%)\n",
      "Predicted Gla with probability: 0.0957 (or 9.57%)\n",
      "Predicted  DR with probability: 0.0739 (or 7.39%)\n",
      "Predicted any with probability: 0.9620 (or 96.20%)\n",
      "\n",
      "If all worked well, RP and any should be predicted with ps of 91.77% and 96.20%, respectively, whereas the other labels are roughly around 5%. Neat!\n"
     ]
    }
   ],
   "source": [
    "#### TEST IMAGE\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "targets = ['MH', 'RP', 'AMD', 'RVO', 'RD', 'Gla', 'DR', 'any_retina_disease']\n",
    "\n",
    "# Exact means and stds from the training set, third dimension added for compatibility with plotting functions\n",
    "norm_means = [0.22578795, 0.23797078, 1]\n",
    "norm_stds = [0.14651306, 0.11282759, 1]\n",
    "resolution = (384, 512)\n",
    "norm_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize(resolution),                                  \n",
    "    T.Normalize(norm_means, norm_stds),\n",
    "    # remove third channel if present\n",
    "    T.Lambda(lambda x: x[:2,...])\n",
    "])\n",
    "\n",
    "# test image from the external validation set in our study, originally used by Antaki et al. in their external validation set\n",
    "# image shows RP\n",
    "img_url = 'https://i.redd.it/hij0f9pkqn441.jpg'\n",
    "!wget https://i.redd.it/hij0f9pkqn441.jpg?raw=true -O test_img_RP.jpg\n",
    "img = Image.open('test_img_RP.jpg')\n",
    "# transform and add a dummy batch dim by unsqueezing\n",
    "img_normalized = norm_transform(img).unsqueeze(0)\n",
    "# expected output (in probability rather than logit space)\n",
    "expected_output = torch.tensor([0.0622, 0.9177, 0.0537, 0.0322, 0.0666, 0.0957, 0.0739, 0.9620])\n",
    "\n",
    "with torch.no_grad():\n",
    "    actual_output = model(img_normalized).flatten()\n",
    "    # apply sigmoid to convert to probs\n",
    "    actual_output = torch.sigmoid(actual_output)\n",
    "    print(f'Actual output:   {actual_output}')\n",
    "    print(f'Expected output: {expected_output}')\n",
    "    print(f'Diff (rounded):  {expected_output - actual_output.round(decimals=4)}')\n",
    "\n",
    "print('\\nThis external validation set image (adapted from Antaki et al.\\'s external validation set, which also includes this image) shows RP.\\n'\\\n",
    "      'So, our model should predict RP and \"any\" (i.e. any disease) with high probabilities,\\n'\\\n",
    "      'and the rest with low probabilities (bearing in mind that we used label smoothing,\\n'\\\n",
    "      'so our model tries to predict approximately 5% if a label is absent and 99% if it is present.)'\\\n",
    "      '\\n\\nHere is what we got:')\n",
    "\n",
    "for predicted_probability, label_name in zip(actual_output, targets):\n",
    "    print(f'Predicted {label_name[:3]:>3} with probability: {predicted_probability.item():.4f} (or {predicted_probability.item()*100:.2f}%)')\n",
    "    \n",
    "print('\\nIf all worked well, RP and any should be predicted with ps of 91.77% and 96.20%, respectively, whereas the other labels are roughly around 5%. Neat!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
